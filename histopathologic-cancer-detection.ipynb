{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image\nfrom tensorflow import keras\nfrom typing import Tuple\nfrom keras.layers import MaxPool2D, Conv2D, Flatten, Dense, BatchNormalization, Activation, Dropout\nfrom keras import Sequential\nfrom sklearn.metrics import auc, roc_curve\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.utils.vis_utils import plot_model\n\nFILE_PATH_BASE = '/kaggle/input/histopathologic-cancer-detection'\nTRAIN_FILES_PATH = f'{FILE_PATH_BASE}/train/'\nTEST_FILES_PATH = f'{FILE_PATH_BASE}/test/'\nTRAIN_LABELS_PATH = f'{FILE_PATH_BASE}/train_labels.csv'\nTRAIN_FILES = os.listdir(TRAIN_FILES_PATH)\nTEST_FILES = os.listdir(TEST_FILES_PATH)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Description of the project, data and objectives\nThis project main objective is to develop an algorithm that is able to identify metastatic cancer in small image patches taken from larger digital pathology scans. The performance of the model will be evaluated on the area under the ROC curve between the predicted probability and the observed target. The data is already divided into two separate folders:\n\n1. Train data\n2. Test data\n\nAnd has a separate file with the true labels of the train data as a CSV file.\n\nHere is the size and dimensions of the data:","metadata":{}},{"cell_type":"code","source":"n_samples_train = len(TRAIN_FILES)\nn_samples_test = len(TEST_FILES)\nimage = plt.imread(f'{FILE_PATH_BASE}/train/{TRAIN_FILES[0]}')\nprint(image.shape)\nprint(f'Number of training images: {n_samples_train}')\nprint(f'Number of test images: {n_samples_test}')\nprint(f'Number of total images: {n_samples_train+n_samples_test}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset contains 277,483 total images, with 220,025 ($\\approx$ 80%) images for training and 57,458 ($\\approx$ 20%) images for testing. After loading one image we can see the dimensions are 96 X 96 X 3.","metadata":{}},{"cell_type":"markdown","source":"# EDA\nBelow there is a sample of pathology images that are positive and negative. After a brief research on how the images are classified by specialists(I am not one by any means), it seems that the main difference between them are the shape of the tissue in the tumors. If it has irregular shape and size, then this might indicate metastatic cancer. \n\nIt is also important to note the following detail in the instruction: \"A positive label indicates that the center 32x32px region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label. This outer region is provided to enable fully-convolutional models that do not use zero-padding, to ensure consistent behavior when applied to a whole-slide image\"","metadata":{}},{"cell_type":"code","source":"train_labels_df = pd.read_csv(TRAIN_LABELS_PATH)\nsample_true, sample_false = train_labels_df.query('label == 1').sample(10)['id'].values,train_labels_df.query('label == 0').sample(10)['id'].values\nfig = plt.figure(figsize=(25, 4))\nfor idx, id_ in enumerate(sample_true):\n    ax = fig.add_subplot(1, 10, idx + 1, xticks=[], yticks=[])\n    ax.set_title('True')\n    p = f'{FILE_PATH_BASE}/train/{id_}.tif'\n    im = Image.open(p)\n    plt.imshow(im)\nfig = plt.figure(figsize=(25, 4))\nfor idx, id_ in enumerate(sample_false):\n    ax = fig.add_subplot(1, 10, idx + 1, xticks=[], yticks=[])\n    ax.set_title('False')\n    p = f'{FILE_PATH_BASE}/train/{id_}.tif'\n    im = Image.open(p)\n    plt.imshow(im)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counts = train_labels_df.label.value_counts()\nf_counts, t_counts = counts\nprint(f'False counts: {f_counts},',f'True counts: {t_counts},', f'Imbalance Ratio: {round(f_counts/t_counts,2)}')\nfig, ax = plt.subplots()\nax.pie(counts, labels=['False', 'True'], autopct='%1.1f%%')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset is imbalanced, it will be best to try to balance it. \n\nThe plan for the analysis and the architecture will be the following.\n* Further separate the training dataset, into training and validation (80-20) split.\n* Balance the dataset\n* Use a convolutional neuron network to compress the images\n* Tweak hyperparameters such as the number of filters, number of layers, activation functions, loss function and learning rate\n* Compute the chart for the loss of training vs validation over EPOCH's\n* Predict test data and get the results.","metadata":{}},{"cell_type":"code","source":"train_labels_df_balanced = pd.concat([train_labels_df[train_labels_df.label == 1], train_labels_df[train_labels_df.label == 0].sample(89117)])\ncounts = train_labels_df_balanced.label.value_counts()\ntrain_labels_df_balanced = train_labels_df.sample(frac=1)\nf_counts, t_counts = counts\nprint(f'False counts: {f_counts},',f'True counts: {t_counts},', f'Imbalance Ratio: {round(f_counts/t_counts,2)}')\nfig, ax = plt.subplots()\nax.pie(counts, labels=['False', 'True'], autopct='%1.1f%%')\nplt.show()\ntrain_labels_df_balanced.to_csv('/kaggle/working/balanced_train_labels.csv', index=False)\ntrain_labels_df.to_csv('/kaggle/working/train_labels.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class project_data:\n    def __init__(self, train_path: str, test_path: str, csv_label_path: str, seed: int, batch_size: int = 32, validation_split = 0.2, target_size: Tuple[int,int] = (96,96), y_col: str = 'label'):\n        self.batch_size = batch_size\n        self.target_size = target_size\n        self.y_col = y_col\n        self.df_label_mapping = pd.read_csv(csv_label_path).assign(\n            file_name = lambda df_: df_.id + '.tif',\n        )\n        self.df_label_mapping[y_col] = self.df_label_mapping[y_col].astype('str')\n        self.df_test_mapping = pd.DataFrame([\n            [f[:-4],f] for f in TEST_FILES #READING GLOBAL VARIABLE TO AVOID DUPLICATE LOAD\n        ], columns = ['id','file_name'])\n        image_gen = ImageDataGenerator(\n            rescale= 1./255,\n            validation_split= validation_split\n        )\n        self.train_generator = image_gen.flow_from_dataframe(\n            dataframe=self.df_label_mapping,\n            directory=train_path,\n            x_col='file_name',\n            y_col=y_col,\n            target_size=target_size,\n            batch_size=batch_size,\n            class_mode='binary',\n            color_mode='rgb',\n            shuffle=True,\n            seed=seed,\n            subset='training'\n        )\n        self.validation_generator= image_gen.flow_from_dataframe(\n            dataframe=self.df_label_mapping,\n            directory=train_path,\n            x_col='file_name',\n            y_col=y_col,\n            target_size=target_size,\n            batch_size=batch_size,\n            class_mode='binary',\n            color_mode='rgb',\n            shuffle=True,\n            seed=seed,\n            subset='validation'\n        )\n        self.test_generator = ImageDataGenerator(\n            rescale= 1./255\n        ).flow_from_dataframe(\n            dataframe=self.df_test_mapping,\n            directory=test_path,\n            x_col='file_name',\n            y_col=None,\n            target_size=target_size,\n            batch_size=batch_size*2,\n            class_mode=None,\n            color_mode='rgb',\n            shuffle=False\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = project_data(TRAIN_FILES_PATH, TEST_FILES_PATH, 'balanced_train_labels.csv', seed=2023)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture\nA Convolutional Neural Network seems like the best approach to use as a model.\nI tried different architectures but the one that had the best performance has the following:\n1. Three convolutional layers (convolutional layer, normalization, activation: relu, convolutional layer, normalization, activation: relu, max pool) with no. filters (32,64,96), kernels (3,3)\n2. A densely connected neural network with 256 units\n3. A final densenly connected network with a sigmoid activation function\n\nI played around with different parameters like input size, number of filters, normalization, data augmentation (flips & rotations, etc), number of parameters, dropout, learning rate, optimization, epochs etc.","metadata":{}},{"cell_type":"code","source":"gpus = tf.config.list_logical_devices('GPU')\nprint(\"Number of available GPUs: \", len(gpus))\nstrategy = tf.distribute.MirroredStrategy(gpus)\nwith strategy.scope():\n    model = Sequential([\n        Conv2D(data.batch_size, (3,3), input_shape=(96,96,3)),\n        BatchNormalization(),\n        Activation('relu'),\n        Conv2D(data.batch_size, (3,3)),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPool2D(2,2),\n        \n        Conv2D(data.batch_size*2, (3,3)),\n        BatchNormalization(),\n        Activation('relu'),\n        Conv2D(data.batch_size*2, (3,3)),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPool2D(2,2),\n        \n        Conv2D(data.batch_size*3, (3,3)),\n        BatchNormalization(),\n        Activation('relu'),\n        Conv2D(data.batch_size*3, (3,3)),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPool2D(2,2),\n        \n        Flatten(),\n        Dense(256, use_bias=False),\n        BatchNormalization(),\n        Activation('relu'),\n        Dropout(0.5),\n        \n        Dense(1,activation='sigmoid')\n    ])\n    \n    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\nhistory = model.fit(\n    data.train_generator,\n    epochs = 10,\n    validation_data=data.validation_generator,\n    verbose=1,\n    callbacks=[\n        EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto', restore_best_weights=True),\n        \n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\ndisplay(Image.open('model.png'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Validation","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_results = model.predict(data.test_generator)\ntest_labels = np.round(np.where(test_results > 0.5, 1, 0).flatten()).astype(int)\ndf = data.df_test_mapping[['id']]\ndf[\"label\"] = test_labels\ndf.to_csv('/kaggle/working/final_result.csv', index=False)\npd.read_csv('/kaggle/working/final_result.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results, Analysis and Conclusion\nAfter a lot of playing with hyperparamaeters this is the best result I managed to get with a private/public score of (0.858, 0.8907). \n\nIt seems the model overfits the data, and working with dropoff layers, early stopping and reducing the learning rate with tensorflow callbacks did not improve my results.\n\nOne of the difficulties I encountered was to work in batches with the tensorflow library, perhaps working with pytorch would have been easier. Balancing the dataset improved a little bit, and probably I could also tweak the model to include more layers, but working with restricted resources in Kaggle took a long time to tune epochs, learning rates, etc.","metadata":{}}]}